{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs1_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyrULTuzHVFF"
      },
      "source": [
        "#Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "! pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from time import time\n",
        "import joblib\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McyCzkUYpcBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d44e70-2abf-4768-c163-fa0b3d9049da"
      },
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKRy_k7EM24L",
        "outputId": "da929cfe-c43e-445a-b818-2df023a56190"
      },
      "source": [
        "#test data\n",
        "test=pd.read_csv('/content/drive/MyDrive/CS1_bo/testpoints.csv')\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(385987, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHUqi2RPNHxe",
        "outputId": "11afae8a-6f86-4198-c23b-55d32d3b3161"
      },
      "source": [
        "y=test['went_on_backorder']\n",
        "X=test.drop(['went_on_backorder','Unnamed: 0'],axis=1)\n",
        "print(X.shape,y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(385987, 22) (385987,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfVs9dESYL3J"
      },
      "source": [
        "def predict(X):\n",
        "  '''This function takes a datapoint as input , preprocess and predict using a pretrained model and returns prediction as output'''\n",
        "  \n",
        "  start=time()\n",
        "  inp=np.array(X)  #input\n",
        "  \n",
        "  #preprocessing\n",
        "  inp=np.where(inp=='Yes',1,inp)   \n",
        "  inp=np.where(inp=='No',0,inp)\n",
        "  \n",
        "  features=dict()\n",
        "  features['national_inv']=inp[1]\n",
        "  features['lead_time']=inp[2]\n",
        "  features['in_transit_qty']=inp[3]\n",
        "  features['forecast_3_month']=inp[4]\n",
        "  features['sales_3_month']=inp[8]\n",
        "  features['min_bank']=inp[11]\n",
        "  features['pieces_past_due']=inp[13]\n",
        "  features['perf_6_month_avg']=inp[14]\n",
        "  features['perf_12_month_avg']=inp[15]\n",
        "  features['deck_risk']=inp[17]\n",
        "  features['stop_auto_buy']=inp[20]\n",
        "  \n",
        "  # values for missing value imputation\n",
        "  impute={'deck_risk': 0.0,\n",
        "          'forecast_3_month': 0.0,\n",
        "          'in_transit_qty': 0.0,\n",
        "          'lead_time': 8.0,\n",
        "          'min_bank': 0.0,\n",
        "          'national_inv': 15.0,\n",
        "          'perf_12_month_avg': 0.83,\n",
        "          'perf_6_month_avg': 0.722,\n",
        "          'pieces_past_due': 0.0,\n",
        "          'sales_3_month': 0.48,\n",
        "          'stop_auto_buy': 1.0}\n",
        "  # columns to tranform\n",
        "  skewed=['in_transit_qty','forecast_3_month','sales_3_month',\n",
        "          'min_bank','pieces_past_due','reorder_point','usable_stock']\n",
        "  \n",
        "  skewed2=['forecast_3_month','sales_3_month','min_bank','perf_6_month_avg']\n",
        "  \n",
        "  to_scale=['national_inv', 'lead_time', 'in_transit_qty',\n",
        "      'forecast_3_month', 'sales_3_month', \n",
        "      'min_bank', 'pieces_past_due']\n",
        "  #scaler\n",
        "  scaler=joblib.load('/content/drive/MyDrive/CS1_bo/scaler.pkl')\n",
        "  base_models=[]\n",
        "  base_predictions=[]\n",
        "  threshold=0.00815\n",
        "  \n",
        "  for i in range(1,16):\n",
        "    base= joblib.load('/content/drive/MyDrive/CS1_bo/model'+str(i)+'.pkl')\n",
        "    base_models.append(base)\n",
        "  meta=joblib.load('/content/drive/MyDrive/CS1_bo/metaclf_.pkl')\n",
        "  \n",
        "  \n",
        "  #missing value imputation\n",
        "  if features['perf_6_month_avg']==-99:\n",
        "    features['perf_6_month_avg']=impute['perf_6_month_avg']\n",
        "  if features['perf_12_month_avg']==-99:\n",
        "    features['perf_12_month_avg']=impute['perf_12_month_avg']\n",
        "  for i in features.keys():\n",
        "    if (features[i]=='NaN')|(features[i]=='nan')|(np.isnan(features[i])):\n",
        "      features[i]=impute[i]\n",
        "  \n",
        "  #feature engg\n",
        "  features['reorder_point']=np.round(((features['sales_3_month']/30)*features['lead_time'])+features['min_bank'],5)\n",
        "  features['usable_stock']=np.round(features['national_inv']-features['reorder_point'],5)\n",
        "  features['neg_stock']=(features['usable_stock']<0).astype('int32')\n",
        "  features['zero_stock']=(features['usable_stock']==0).astype('int32')\n",
        "  features['min_stock']=(features['usable_stock']<features['min_bank']).astype('int32')\n",
        "  \n",
        "  \n",
        "  #feature transformations\n",
        "  for feat in skewed:\n",
        "    features[feat]= np.round(np.log(abs(features[feat])+1)*np.sign(features[feat]),5)\n",
        "  for feat in skewed2:\n",
        "    features[feat]=np.round((features[feat])**2,5)\n",
        "  \n",
        "  features['pieces_past_due']=np.round((features['pieces_past_due'])**4,5)\n",
        "  features['usable_stock']=np.round(((features['usable_stock'])**2)*np.sign(features['usable_stock']),5)\n",
        "  \n",
        "  #scaling\n",
        "  scaled=scaler.transform(np.array([features[v] for v in to_scale]).reshape(1,-1))\n",
        "  for i,v in enumerate(to_scale):\n",
        "    features[v]=np.round(scaled[0][i],6)\n",
        "  \n",
        "  all_cols=['national_inv', 'lead_time', 'in_transit_qty',\n",
        "       'forecast_3_month', 'sales_3_month', 'min_bank', 'pieces_past_due',\n",
        "       'perf_6_month_avg', 'perf_12_month_avg', 'deck_risk', 'stop_auto_buy',\n",
        "        'reorder_point', 'usable_stock', 'neg_stock','zero_stock', 'min_stock']\n",
        "  #preprocessd data\n",
        "  preprocessed=np.array([features[value] for value in all_cols]).reshape(1,-1)\n",
        "  \n",
        "  #prediction by base models\n",
        "  for model in base_models:\n",
        "    base_predictions.append(model.predict_proba(preprocessed)[0][1])\n",
        "  \n",
        "  #meta model prediction\n",
        "  meta=joblib.load('/content/drive/MyDrive/CS1_bo/metaclf_.pkl')\n",
        "  prediction=meta.predict_proba(np.array(base_predictions).reshape(1,-1))[0][1]\n",
        "  prediction=(prediction>=threshold).astype('int32')\n",
        "  print('prediction:',prediction )\n",
        "  print('time taken: %0.2f seconds'%(time()-start))\n",
        "  \n",
        "  return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PHDdigwK9UF",
        "outputId": "22500caf-b547-4c52-933b-defa5de01f6b"
      },
      "source": [
        "#predict a point\n",
        "predict(test.iloc[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction: 0\n",
            "time taken: 2.53 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql3GAisi9DU0"
      },
      "source": [
        "def evaluate(X,y):\n",
        "  '''This function take a dataframe as input , preprocess and predict using a pretrained model and returns prediction and roc-auc score as output'''\n",
        "  start=time()\n",
        "  data=X\n",
        "  #columns\n",
        "  all_cols=['national_inv', 'lead_time', 'in_transit_qty',\n",
        "       'forecast_3_month', 'sales_3_month', 'min_bank', 'pieces_past_due',\n",
        "       'perf_6_month_avg', 'perf_12_month_avg', 'deck_risk', 'stop_auto_buy',\n",
        "        'reorder_point', 'usable_stock', 'neg_stock','zero_stock', 'min_stock']\n",
        "  #values for imputation\n",
        "  impute={'deck_risk': 0.0,\n",
        "          'forecast_3_month': 0.0,\n",
        "          'in_transit_qty': 0.0,\n",
        "          'lead_time': 8.0,\n",
        "          'min_bank': 0.0,\n",
        "          'national_inv': 15.0,\n",
        "          'perf_12_month_avg': 0.83,\n",
        "          'perf_6_month_avg': 0.722,\n",
        "          'pieces_past_due': 0.0,\n",
        "          'sales_3_month': 0.48,\n",
        "          'stop_auto_buy': 1.0,\n",
        "            }\n",
        "  #features to transform\n",
        "  skewed=['in_transit_qty','forecast_3_month','sales_3_month',\n",
        "          'min_bank','pieces_past_due','reorder_point','usable_stock']\n",
        "  skewed2=['forecast_3_month','sales_3_month','min_bank','perf_6_month_avg']\n",
        "\n",
        "  #features to scale\n",
        "  to_scale=['national_inv', 'lead_time', 'in_transit_qty',\n",
        "      'forecast_3_month', 'sales_3_month', \n",
        "      'min_bank', 'pieces_past_due']\n",
        "  \n",
        "  #scaler\n",
        "  scaler=joblib.load('/content/drive/MyDrive/CS1_bo/scaler.pkl')\n",
        "  \n",
        "  #load base models\n",
        "  base_models=[]\n",
        "  for i in range(1,16):\n",
        "    base= joblib.load('/content/drive/MyDrive/CS1_bo/model'+str(i)+'.pkl')\n",
        "    base_models.append(base)\n",
        "  \n",
        "  #load meta model\n",
        "  meta=joblib.load('/content/drive/MyDrive/CS1_bo/metaclf_.pkl')\n",
        "  \n",
        "  base_predictions=[]\n",
        "  threshold=0.00815\n",
        "  \n",
        "  #drop nan\n",
        "  data.dropna(thresh=5,inplace=True)\n",
        "  \n",
        "  #replace 'Yes'/'No' with 1/0 & missing value imputation\n",
        "  for feat in impute.keys():\n",
        "    if data[feat].dtype=='O':\n",
        "      data[feat]=data[feat].replace({'Yes': 1,'No': 0})\n",
        "    data[feat].fillna(impute[feat],inplace=True)\n",
        "  \n",
        "  data['perf_6_month_avg'] = data['perf_6_month_avg'].replace([-99],impute['perf_6_month_avg'])\n",
        "  data['perf_12_month_avg'] = data['perf_12_month_avg'].replace([-99],impute['perf_12_month_avg'])\n",
        "   \n",
        "  #feature engg\n",
        "  data['reorder_point']=np.round(((data['sales_3_month']/30)*data['lead_time'])+data['min_bank'],5)\n",
        "  data['usable_stock']=np.round(data['national_inv']-data['reorder_point'],5)\n",
        "  data['neg_stock']=(data['usable_stock']<0).astype('int32')\n",
        "  data['zero_stock']=(data['usable_stock']==0).astype('int32')\n",
        "  data['min_stock']=(data['usable_stock']<data['min_bank']).astype('int32')\n",
        "\n",
        "  #feature transformations\n",
        "  data['in_transit_qty']=data['in_transit_qty'].apply(lambda x: np.log(abs(x)+1)*np.sign(x))\n",
        "  data['forecast_3_month']=data['forecast_3_month'].apply(lambda x: np.log(abs(x)+1)*np.sign(x))\n",
        "  data['forecast_3_month']=data['forecast_3_month'].apply(lambda x: x**2)\n",
        "  data['sales_3_month']=data['sales_3_month'].apply(lambda x: np.log(abs(x)+1)*np.sign(x))\n",
        "  data['sales_3_month']=data['sales_3_month'].apply(lambda x: x**2)\n",
        "  data['min_bank']=data['min_bank'].apply(lambda x: np.log(abs(x)+1)*np.sign(x))\n",
        "  data['min_bank']=data['min_bank'].apply(lambda x:x**2)\n",
        "  data['pieces_past_due']=data['pieces_past_due'].apply(lambda x: np.log(abs(x)+1)*np.sign(x))\n",
        "  data['pieces_past_due']=data['pieces_past_due'].apply(lambda x: x**4)\n",
        "  data['perf_6_month_avg']=data['perf_6_month_avg'].apply(lambda x: x**2)\n",
        "  data['reorder_point']=data['reorder_point'].apply(lambda x: np.log(abs(x)+1)*np.sign(x))\n",
        "  data['usable_stock']=data['usable_stock'].apply(lambda x: np.log(abs(x)+1)*np.sign(x))\n",
        "  data['usable_stock']=data['usable_stock'].apply(lambda x: (x**2)*np.sign(x))\n",
        "  \n",
        "  data=data.loc[:,all_cols]\n",
        "  data[to_scale]=scaler.transform(data[to_scale])\n",
        "  \n",
        "  #predictions\n",
        "  for model in base_models:\n",
        "    base_predictions.append(model.predict_proba(data)[:,1])\n",
        "  base_predictions=np.transpose(np.array(base_predictions))\n",
        "  yhat=meta.predict_proba(base_predictions)[:,1]\n",
        "  score=roc_auc_score(y,yhat)\n",
        "  print('time taken: %0.2f seconds'%(time()-start))\n",
        "  joblib.dump(yhat,'/content/drive/MyDrive/CS1_bo/test_prediction_'+str(int(time()))+'.pkl')\n",
        "  \n",
        "  \n",
        "  return score,yhat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etvEA8l5LLJU",
        "outputId": "848ff626-dfe8-495f-cc52-41b2eba807c3"
      },
      "source": [
        "#evaluate model\n",
        "score,yhat=evaluate(X,y)\n",
        "print('ROC AUC :',score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time taken: 233.11 seconds\n",
            "ROC AUC : 0.9639302290240149\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}